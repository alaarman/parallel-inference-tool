%!TEX root = main.tex

\section{Introduction}
\label{sec:introduction}

Hazard and safety analysis are important tools to mitigate risks and prevent disaster in many industries. The complicated interactions between industrial processes and production chains are often modeled in fault trees~\cite{ruijters2015fault}, Bayesian networks~\cite{pearl2011bayesian} and other graphical models~\cite{kollerfriedman2009}, which enable reasoning under uncertainty.
Many reasoning tasks are however hard and occur frequently. To remedy this problem, knowledge compilation aims to find a concise representation that enables fast queries on the same model.

For this purpose, many representation languages~\cite{darwiche2001decomposable,darwiche2002logical,darwiche2011sdd,darwiche2002knowledge,fargier2014knowledge,sanner2005affine,tafertshofer1997factored} have een studied analytically, as well as in practice, demonstrating a clear tradeoff between the succinctness of the language ---with often exponential separations--- and the tractability of important operations on them. These operations can roughly be divided into manipulation operations and queries. The latter play an important role in the compilation step, which builds the knowledge base, while the former is used to query it. For this reason, the budget for manipulation operations is often greater, since this step needs to happen only once.

To the best of our knowledge\todo{please check me on this}, \toolname is the first parallel knowledge compilation and inference tool for Bayesian networks. It compiles networks into the Weighted-Positive Binary Decision Diagram (WPBDD). Our chosen parallelization approach through partitioning can reduce the effort spent on compilation because the decomposition of a propositional theory is known to yield smaller symbolic representations, which has previously been shown in model checking~\cite{narayan1996partitioned,sahoo2004partitioning,grumberg2006work}. Empirical results with \toolname confirm this~\cite{dal2017reducing}.
 This improvement is offset by a potential increase in the time spent on inference, although our experiments still demonstrate good performance due to the smaller representations. The parallelization approach is orthoganal with regard to target representation languages~\cite{dal2018parallel}, as we demonstrated with four different representations.

The performance of \toolname compares favorably~\cite{dal2018parallel} against other knowledge compilers, like  SDD\footnote{Available at \url{http://reasoning.cs.ucla.edu/sdd}}, CUDD\footnote{Available at \url{http://vlsi.colorado.edu/~fabio}} and ACE\footnote{Available at \url{http://reasoning.cs.ucla.edu/ace}}, which target SDD~\cite{darwiche2011sdd}, OBDD~\cite{bryant1986graph} and d-DNNF~\cite{darwiche2002knowledge}, respectively.
The scalability of the tool is good for larger networks and for both compilation and inference, exhibiting over tenfold speedups on 64 cores.





%\todo[inline]{
%A motivation as to why the tool is interesting and significant should be provided. Further, the paper should describe aspects such as, for example, the assumptions about application domain and/or extent of potential generality, demonstrate the tool workflow(s), explain integration and/or human interaction, evaluate the overall role and the impact to the development process.
%}


