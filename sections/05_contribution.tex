%!TEX root = main.tex


\section{Parallel Compilation and Inference}
\label{secjjparallel}

\begin{figure}[!t]
    \centering
    \scalebox{0.6}{
        \input{figures/overview.tex}
    }
    \caption{The compositional framework.}
    \label{fig:frameworkoverview}
\end{figure}

\begin{figure}[!t]
    \centering
    \input{figures/implementation.tex}
    \caption{The implementation.}
    \label{fig:implementation}
\end{figure}


% Let's back up for a moment, by describing the means to this end.
AS BNs are defined over multi-valued domains, to encode the probability distribution it represents, we require an encoding is to transition from the multi-valued domain to the Boolean domain. There are multiple ways to do this, but \toolname chooses to first translate a BN into a satisfiability (SAT) instance in Conjunctive Normal Form (CNF) with dedicated variables to represent probabilities~\cite{dal2017wpbdd} (in this step we do not need to introduce extra variables as e.g. a Tseitin transformation would).

The SAT instance serves as an entry point into for the compilers to create a binary decision diagram (BDD), for instance. Compiling a BN into a BDD-like representations is commonly referred to as \emph{knowledge compilation}~\cite{darwiche2002knowledge}, or simply compilation. The \toolname compiler however specifically targets \emph{Weighted Positive Binary Decision Diagrams} (WPBDD), which is a dedicated representation for this purpose. (We discuss differences with other representations in Section~\ref{sec:conclusion}.)
	In addition, the compiler introduces a partitioning to further improve overall performance.

Figure~\ref{fig:frameworkoverview} shows a high level overview of the tool's internal processes. \toolname implements WMC in two major parts: \emph{compilation} and \emph{inference}. Let's dive into the compilation part. Given a user provided number of partitions, a partitioning is found for the BN. This partitioning is optimized by minimizing the sum of each partitions tree-width using \emph{simulated annealing}. Tree-width is a metric commonly use to indicate the complexity of BNs~\cite{bollig2014width}.

With the partitioning in hand, the following steps can be performed in parallel, per partition. Theoretically, compilation is as fast as the slowest compiling partition~\cite{dal2018parallel}. Each partition is considered an independent BN from this point on. The BN is encoded as a Boolean formula as previously mentioned~\cite{chavira2008probabilistic}. \toolname takes this Boolean formula and compiles it to a WPBDD. The most expensive operation amongst them all. Performance is primarily determined by this step. We have now reached the end of the compilation part as indicated by Figure~\ref{fig:frameworkoverview}, yielding a WPBDD per partition.

We arrive at the inference part of \toolname. The upside of getting this far, is the computational complexity of inference is linear in the size of the target representation~\cite{darwiche2002knowledge}, in our case a WPBDD. Inference is performed by traversing the target representation whilst evaluating the underlying arithmetic formula. The arithmetic formula is different for every target representation, but generally we can convert a logical OR to addition, logical AND to multiplication, and substitute variables with the value or probability they represent. All that is left, is to evaluate this formula in order to obtain the marginal probability we seek.

In case we chose to partition the BN, we compose the obtained WPBDDs and create a monolithic WPBDD. A partition is connected to another of they share a common variable. This implies that order in which we traverse partitions is not a total ordering. It is partial, and can be represented by a tree.The order in which we choose to traverse partitions determines how they are connected. As we traverse one partition, its sink is connected to the next partitions root.

