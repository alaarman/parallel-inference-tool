%!TEX root = main.tex

\section{Probabilistic Inference using Decision Diagrams}\label{sec:parallel}


Bayesian networks represent concise factorizations of probability distributions by using conditional independence assumptions. The size of the factorization has direct implications toward the cost of reasoning, i.e., probabilitic inference. A more expressive model must be used to further improve a BN's factorization in order to exploit additional independences~\cite{boutilier1996context,friedman1998learning,zhang1996exploiting}. A prominent way of achieving this is by using Boolean algebra to find a more concise and canonical representation, such as a Binary Decision Diagrams (BDD). Compiling a BN into a BDD-like representations is commonly referred to as \emph{knowledge compilation}~\cite{darwiche2002knowledge}, or simply compilation.

\begin{figure}[!t]
    \centering
    \scalebox{0.9}{
        \input{figures/overview.tex}
    }
    \caption{The compositional framework.}
    \label{fig:frameworkoverview}
\end{figure}


Figure~\ref{fig:frameworkoverview} shows an overview of the underlying principles behind probablistic inference using BDDs, divided into two steps: \emph{compilation} and \emph{inference}. We will dive into these steps in the following sections without going into too much detail. In-depth descriptions can be found in~\cite{dal2021compositional}.

\subsection{Compilation}

We first describe compilation as being all steps required to obtain a BDD. In addition to traditional compilation, we introduce partitioning to further improve overall performance~\cite{dal2017reducing}.

A partitioning is found for the BN. This partitioning is optimized by minimizing the sum of each partition's tree-width. Tree-width is a metric commonly used to indicate the complexity of BNs~\cite{bollig2014width}. With the partitioning in hand, the following steps can be performed independently, per partition. Theoretically, compilation is as fast as the slowest compiling partition~\cite{dal2018parallel}. Each partition is considered an independent BN from this point on.

BNs are defined over multi-valued domains. Prior to compiling it to a BDD, we require an encoding to transition from the multi-valued domain to the Boolean domain. There are multiple ways to do this. We chooses to first translate a BN into a satisfiability (SAT) instance in Conjunctive Normal Form (CNF) with dedicated variables to represent probabilities~\cite{chavira2008probabilistic,dal2017wpbdd} (in this step we do not need to introduce extra variables as e.g. a Tseitin transformation would).

The obtained SAT instance serves as an entry point into the field of language compilers~\cite{dudek2020addmc}. These compilers target different variations of BDDs. The process of compiling a SAT instance to a respective BDD using one such compiler is by far the most expensive operation of the entire process. Performance is primarily determined by this step, while inference if mich cheaper.

With monolithic compilation, we would only be able to amortize cost of compilation by performing many inference queries. With partitioned compilation, we shift some of this cost over to the inference side, yielding overall performance improvements in cases where we would traditionally not be able to achieve sufficient amortization~\cite{dal2017reducing}. We have now reached the end of the compilation part as indicated by Figure~\ref{fig:frameworkoverview}.

\subsection{Inference}\label{subsec:inference}

After compilation we arrive at the inference step. The upside of getting this far, is that the computational complexity of inference is linear in the size of the target representation~\cite{darwiche2002knowledge}. Inference is performed by traversing the target representation whilst evaluating the underlying arithmetic formula. The arithmetic formula is different for every target representation, but generally we can convert a logical OR to addition, logical AND to multiplication, and substitute variables with the value or probability they represent. All that is left, is to evaluate this formula in order to obtain the marginal probability we seek. In short, this is inference by \emph{Weighted Model Counting} (WMC)~\cite{chavira2008probabilistic}.

In case we chose to partition the BN during the compilation step, we have to compose the compiled BDDs and create a monolithic representation. A partition's representation is connected to another of they share a common variable. This implies that the order in which we traverse partitions is not a total ordering, it is partial. It can be represented by a tree, we suitably refer to as a composition-tree~\cite{dal2021compositional}. The order in which we choose to traverse partitions determines how they are connected. As we traverse one partition, its sink is connected to the next partition's root. Now that all partitions form one connected component, we can proceed as previous described with a traversal we are already familier with from WMC.


\section{\toolname}

We present \toolname in Figure~\ref{fig:implementation}. It implements the principles outlined in Figure~\ref{fig:frameworkoverview} and Section~\ref{sec:parallel}. \toolname is a collection of two applications written in C++. The compilation step is implemented by the \verb+COMPILER+, whereas the inference step is implemented by the \verb+INFERENCE ENGINE+. We will proceed to discuss their internal processes in the following sections.

\begin{figure}[!t]
    \centering
    \input{figures/implementation.tex}
    \caption{The implementation.}
    \label{fig:implementation}
\end{figure}

\subsection{The \texttt{COMPILER}}

The \verb+COMPILER+ takes as input a BN encoded in the HUGIN format~\cite{madsen2003hugin}. The compiler is responsible for creating a decision diagram from the provided BN. The principles outlined in Section~\ref{sec:parallel} provide an orthogonal framework with regard to the target representation. However, \toolname chooses to target \emph{Weighted Positive Binary Decision Diagrams} (WPBDD), because it is a dedicated representation for probabilistic inference. (We discuss differences with other representations in Section~\ref{sec:conclusion}.)

The \texttt{COMPILER} can introduce a partitioning to further improve overall performance~\cite{dal2017reducing}. With a user provided number of partitions, a partitioning is found for the BN. Using simulated annealing, this partitioning is optimized by minimizing the sum of each partition's tree-width. Tree-width is a metric commonly used to indicate the complexity of BNs~\cite{bollig2014width}. Optionally, a partitioning can also be provided by the user. With the partitioning in hand, the following steps can be performed in parallel, per partition. Theoretically, compilation is as fast as the slowest compiling partition~\cite{dal2018parallel}.

Compilation is critically dependent upon a good variable ordering. The size of the resulting WPBDD (or any other ordered BDD) is determined by it. The \texttt{COMPILER} can optionally be provided with a variable ordering as input. When not provided by one, an ordering is created automatically using the min-hill heuristic. Further refinement can be attained when the user requires it. It is achieved by minimizing the tree-width of candidate orderings, using simulated annealing.

To summarize (and as indicated by Figure~\ref{fig:implementation}), the \texttt{COMPILER} takes as input a BN, and optionally accepts a partitioning, and an ordering for each partition. If required, an ordering and parittioning is created automatically, when none are provided. In parallel, each partition is encoded and compiled to the target representation. As output, the compiled representations are written to files, with one WPBDD per from. The partitioning and ordering(s) that were used during compilation are also written to files.

\subsection{The \texttt{INFERENCE ENGINE}}

In its core, the \texttt{INFERENCE ENGINE} is able to perform probabilitic inference through marginalization. It does so using WMC (Section~\ref{subsec:inference}. In extension, we are able to compute conditional probabilities through Bayes' theorem (Section~\ref{sec:background}). Let's say we are interrested in probability $P(X = x | E = e)$:  \[P(X = x | E = e) = \frac{P(X = x, E = e)}{P(E = e)}.\]
We compute this using two marginalizations, i.e., we run WMC two times. Once for $P(X = x, E = e)$ and once for $P(E = e)$. Now let's say that we want to know the posterior probabilities for every of $X$'s $n$ values. Implementing this na\"ively would result in $2$ marginalizations for each value, i.e., $2n$ marginalizations. We reduce this by reusing the divisor for every computation, as it is unchanging. The divisor $P(E = e)$ is computed once, whereas the dinominator $P(X = x, E = e)$ is adjusted for every value. This results in $n + 1$ marginalizations. To further reduce this, we also use the fact marginalizing over $X$ sums to $1$. In other words, we only need to compute the posteriors for $n-1$ values. The last marginalization can be obtained by substracting the sum of the previous marginalizations from $1$. We therefore arive at a total of $(n-1) + 1$ marginalizations, i.e., we only need $n$ marginalizations to compute every posterior for variable $X$.

Notice that each marginalization is an independent run of WMC, just with different variable instantations. A trivial optimization here is that we can run every call to WMC in \emph{parallel}. Theoretically reducing the cost of computing the posterior probabilities for all instantations of unobserved variables combined to the single WMC call that requires the most resources.
\todo {describe that an individual WMC run is also parallelized}


To summarize, the \texttt{INFERENCE ENGINE} takes as input a BN, the compiled WPBDD(s), a variable mapping and optionally the used partitioning. If the BN was partitioned, then the WPBDDs are composed into a monolithic representation prior to WMC using an automatically created composition-tree~\cite{dal2021compositional}. Given the user's set of probabilitic queries, the corresponding marginalizations are performed in parallel. Prior to every WMC run we need to instantiate the variables in the WPBDD, reflecting the marginalization we want to achieve. Proper variable instantiations in the WPBDD are attained by useing the \texttt{COMPILER}'s variable mapping to map BN variables to WPBDD variables. Once all marginializations are obtained, conditional probabilities are computed as previously described.



